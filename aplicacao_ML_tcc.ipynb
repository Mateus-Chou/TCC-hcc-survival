{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from sklearn.model_selection import  KFold\n",
    "# Ocultar todos os avisos\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('hcc-data.txt', na_values='?')\n",
    "cols = ['genero', 'sintomas', 'alcool', 'antigeno_superficie_hepatite_b', 'antigeno_e_hepatite_b', 'antigeno_core_hepatite_B', 'antigeno_hepatite_c','cirrose',\n",
    "'pais_endemico', 'fumante','diabetes','obesidade','hemocromatose', 'hipertensao_arterial', 'insuficiencia_renal_cronica',\n",
    "'HIV','esteato_hepatite_nao_alcoolica', 'varizes_esofagicas', 'esplenomegalia', 'hipertensao_portal', 'trombose_veia_porta',\n",
    "'metastases_hepatica', 'marca_radiologica', 'idade_diagnostico', 'gramas_de_alcool_dia', 'pacotes_cigarro_dia', 'performance_status',\n",
    "'grau_encefalopatia','grau_ascite', 'INR', 'AFP', 'Hemoglobina', 'vol_corpuscular_medio', 'leucocito', 'plaquetas', 'albumina',\n",
    "'biliburrina_total', 'alanina_transaminase', 'aspartato_aminotransferase', 'gama_glutamil_transferase', 'fosfatase_alcalina',\n",
    "'proteina_totais', 'creatina', 'numero_de_nodulos', 'maior_diametro_nodulo', 'biliburrina_direta', 'ferro', 'saturacao_oxigenio', 'ferritina',\n",
    "'sobreviveu_1_ano']\n",
    "df.columns = cols\n",
    "df['morreu_1_ano'] = np.where(df['sobreviveu_1_ano']==1,0,1)\n",
    "alvo = 'morreu_1_ano'\n",
    "df = df.drop(columns='sobreviveu_1_ano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred=['sintomas', 'trombose_veia_porta', 'metastases_hepatica', 'idade_diagnostico', 'grau_ascite', 'INR', 'AFP', 'Hemoglobina', 'plaquetas', 'gama_glutamil_transferase', 'biliburrina_total', 'albumina', 'fosfatase_alcalina', 'maior_diametro_nodulo', 'biliburrina_direta', 'ferro', 'ferritina', 'morreu_1_ano']\n",
    "df = df[cols_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#dytpe = int para retornar os valores em inteiro(1 e 0) e nao booleanos(true e false)\n",
    "df = pd.get_dummies(df, columns=['grau_ascite'], dtype=int)\n",
    "print(df[[\"grau_ascite_1.0\"  ,\"grau_ascite_2.0\"  ,\"grau_ascite_3.0\" ]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = alvo)\n",
    "y = df[alvo]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if len(X_train[col].dropna().unique()) > 2:\n",
    "        # .T transpoe o dataframe \n",
    "        # DQ = distancia interquartil   \n",
    "        df_desc = X_train[col].describe().T\n",
    "        DQ = df_desc['75%'] - df_desc['25%']\n",
    "        limite_inferior = df_desc['25%'] - 1.5*DQ\n",
    "        limite_superior = df_desc['75%'] + 1.5*DQ\n",
    "        # atribui valor nulo aos outliers\n",
    "        X_train.loc[(X_train[col] > limite_superior), col] = limite_superior\n",
    "        X_train.loc[(X_train[col] < limite_inferior), col] = limite_inferior\n",
    "        X_test.loc[(X_test[col] > limite_superior), col] = limite_superior\n",
    "        X_test.loc[(X_test[col] < limite_inferior), col] = limite_inferior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    indexs = X_train[X_train[col].isnull()].index\n",
    "    if len(indexs) > 0:\n",
    "        if len(X_train[col].dropna().unique()) <= 2:\n",
    "            X_train[\"%s_nulo\" % col] = 0\n",
    "            X_train.loc[indexs, col] = X_train[col].mode().values[0]\n",
    "            X_train.loc[indexs, \"%s_nulo\" % col] =  1\n",
    "        else:\n",
    "            X_train[\"%s_nulo\" % col] = 0\n",
    "            X_train.loc[indexs, \"%s_nulo\" % col] = 1\n",
    "            X_train.loc[indexs, col] = X_train[col].mean()\n",
    "for col in X_test.columns:\n",
    "    indexs = X_test[X_test[col].isnull()].index\n",
    "    if len(indexs) > 0:\n",
    "        if len(X_train[col].dropna().unique()) <= 2:\n",
    "            X_test[\"%s_nulo\" % col] = 0\n",
    "            X_test.loc[indexs, col] = X_train[col].mode().values[0]\n",
    "            X_test.loc[indexs, \"%s_nulo\" % col] = 1\n",
    "        else:\n",
    "            X_test[\"%s_nulo\" % col] = 0\n",
    "            X_test.loc[indexs, \"%s_nulo\" % col] = 1\n",
    "            X_test.loc[indexs, col] = X_train[col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adicionando as colunas dummies com tudo 0, pois a amostra de teste nao possue valores nulos no atributo\n",
    "for col in X_train.columns:\n",
    "    if col not in X_test.columns:\n",
    "        X_test[col] = 0\n",
    "X_test = X_test[X_train.columns.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instância do modelo de Random Forest\n",
    "rf_classifier = RandomForestClassifier()\n",
    "#  hiperparâmetros e seus valores a serem testados\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3,5,10, 20, 30],\n",
    "    'min_samples_split': [3, 5,7, 10],\n",
    "    'min_samples_leaf': [3, 6, 9],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_rf = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, scoring='roc_auc')\n",
    "\n",
    "# treina o objeto GridSearchCV aos dados de treinamento\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Acessa os melhores hiperparâmetros encontrados\n",
    "print(\"Melhores hiperparâmetros encontrados (Random Forest):\")\n",
    "print(grid_search_rf.best_params_)\n",
    "# aloca os melhores hiperparametros no modelo\n",
    "params_rf = grid_search_rf.best_params_\n",
    "\n",
    "# instância do modelo de XGboost\n",
    "xgb_classifier = XGBClassifier()\n",
    "#  hiperparâmetros e seus valores a serem testados\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,300],\n",
    "    'max_depth': [3,4,5, 6, 7,8],\n",
    "    'learning_rate': [0.1,0.2, 0.3,0.4, 0.5],\n",
    "}\n",
    "\n",
    "GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=10,n_jobs=2, scoring='roc_auc')\n",
    "\n",
    "# treina o objeto GridSearchCV aos dados de treinamento\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Acessa os melhores hiperparâmetros encontrados\n",
    "print(\"Melhores hiperparâmetros encontrados (XGboost):\")\n",
    "print(grid_search_xgb.best_params_)\n",
    "# aloca os melhores hiperparametros no modelo\n",
    "params_xgb = grid_search_xgb.best_params_\n",
    "\n",
    "# instância do modelo de redes neurais\n",
    "nn_classifier = MLPClassifier()\n",
    "# hiperparâmetros e seus valores a serem testados\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'learning_rate_init': [0.01, 0.1, 0.2],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'momentum': [0.5, 0.9, 0.99],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_nn = GridSearchCV(estimator=nn_classifier, param_grid=param_grid, cv=3, scoring='roc_auc')\n",
    "\n",
    "# treina o objeto GridSearchCV aos dados de treinamento\n",
    "grid_search_nn.fit(X_train, y_train)\n",
    "\n",
    "# Acessa os melhores hiperparâmetros encontrados\n",
    "print(\"Melhores hiperparâmetros encontrados (Redes Neurais):\")\n",
    "print(grid_search_nn.best_params_)\n",
    "# aloca os melhores hiperparametros no modelo\n",
    "params_nn = grid_search_nn.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {'max_depth': 10, 'min_samples_leaf': 6, \n",
    "'min_samples_split': 5, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas que vao ser armazenadas os resultados das predicoes e os verdadeiros valores\n",
    "# pp = resultados em probabilidade e p em classe\n",
    "# rf = randomforest, xg = xgboost, nn = redes neurais\n",
    "y_t = []\n",
    "y_p_rf = []\n",
    "y_pp_rf = []\n",
    "y_p_xg = []\n",
    "y_pp_xg = []\n",
    "y_p_nn = []\n",
    "y_pp_nn = []\n",
    "x_train_all = []\n",
    "y_train_all = []\n",
    "\n",
    "for i in (range(40)):\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        # Dividir os dados em conjuntos de treinamento e teste\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # pre processamento ja bisto \n",
    "        for col in X_train.columns:\n",
    "            indexs = X_train[X_train[col].isnull()].index\n",
    "            if len(X_train[col].dropna().unique()) > 2:\n",
    "                df_desc = X_train[col].describe().T\n",
    "                DQ = df_desc['75%'] - df_desc['25%']\n",
    "                limite_inferior = df_desc['25%'] - 1.5*DQ\n",
    "                limite_superior = df_desc['75%'] + 1.5*DQ\n",
    "                X_train.loc[(X_train[col] > limite_superior), col] = limite_superior\n",
    "                X_train.loc[(X_train[col] < limite_inferior), col] = limite_inferior\n",
    "                X_test.loc[(X_test[col] > limite_superior), col] = limite_superior\n",
    "                X_test.loc[(X_test[col] < limite_inferior), col] = limite_inferior\n",
    "                if len(indexs) > 0:\n",
    "                    X_train[\"%s_nulo\" % col] = 0\n",
    "                    X_train.loc[indexs, \"%s_nulo\" % col] = 1\n",
    "                    X_train.loc[indexs, col] = X_train[col].mean()\n",
    "            else:\n",
    "                if len(indexs) > 0:\n",
    "                    X_train[\"%s_nulo\" % col] = 0\n",
    "                    X_train.loc[indexs, col] = 0\n",
    "                    X_train.loc[indexs, \"%s_nulo\" % col] = X_train[col].mode().values[0]\n",
    "        for col in X_test.columns:\n",
    "            indexs = X_test[X_test[col].isnull()].index\n",
    "            if len(indexs) > 0:\n",
    "                if len(X_train[col].dropna().unique()) > 2:\n",
    "                    X_test[\"%s_nulo\" % col] = 0\n",
    "                    X_test.loc[indexs, col] = 0\n",
    "                    X_test.loc[indexs, \"%s_nulo\" % col] = X_train[col].mode().values[0]\n",
    "                else:\n",
    "                    X_test[\"%s_nulo\" % col] = 0\n",
    "                    X_test.loc[indexs, \"%s_nulo\" % col] = 1\n",
    "                    X_test.loc[indexs, col] = X_train[col].mean()\n",
    "        for col1 in X_train.columns:\n",
    "            if col1 not in X_test.columns:\n",
    "                X_test[col1] = 0\n",
    "        X_test = X_test[X_train.columns.tolist()]\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(X_train)\n",
    "        X_train_data = sc.transform(X_train)\n",
    "        X_train = pd.DataFrame(X_train_data, columns = X_train.columns)\n",
    "        X_test_data = sc.transform(X_test)\n",
    "        X_test = pd.DataFrame(X_test_data,columns=X_test.columns)\n",
    "       \n",
    "        # define os modelos com os hiperparametros do gridsearch\n",
    "        random_forest = RandomForestClassifier(**params_rf)\n",
    "        xg_boost = XGBClassifier(**params_xgb)\n",
    "        neural_networks = MLPClassifier(**params_nn)\n",
    "        \n",
    "        #treina os modelos\n",
    "        random_forest.fit(X_train, y_train)\n",
    "        xg_boost.fit(X_train, y_train)\n",
    "        neural_networks.fit(X_train, y_train)\n",
    "\n",
    "        #armazena as predicoes em probabilidade e classe e o resultado real\n",
    "        y_t.extend(y_test)\n",
    "        y_p_rf.extend(random_forest.predict(X_test))\n",
    "        y_pp_rf.extend(random_forest.predict_proba(X_test)[:,1])\n",
    "        y_p_xg.extend(xg_boost.predict(X_test))\n",
    "        y_pp_xg.extend(xg_boost.predict_proba(X_test)[:,1])\n",
    "        y_p_nn.extend(neural_networks.predict(X_test))\n",
    "        y_pp_nn.extend(neural_networks.predict_proba(X_test)[:,1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular as métricas \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "accuracy = accuracy_score(y_t, y_p_xg)\n",
    "recall = recall_score(y_t, y_p_xg)\n",
    "precision = precision_score(y_t, y_p_xg)\n",
    "f1 = f1_score(y_t, y_p_xg)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precisão: {precision}')\n",
    "print(f'F1-Score: {f1}')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calcula a curva ROC e a área sob a curva ROC (ROC AUC)\n",
    "fpr, tpr, thresholds = roc_curve(y_t, y_pp_xg)\n",
    "roc_auc = roc_auc_score(y_t, y_pp_xg)\n",
    "\n",
    "# Plotar a curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (área = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Exibir a plotagem da curva ROC\n",
    "plt.show()\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "cm = confusion_matrix(y_t, y_p_xg)\n",
    "\n",
    "# Definir rótulos das classes\n",
    "class_labels = ['Classe 0', 'Classe 1']\n",
    "\n",
    "# Plotar a matriz de confusão como um gráfico\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusao')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "\n",
    "# Adiciona os valores da matriz de confusão nas células da matriz\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Predição')\n",
    "\n",
    "# Exibe a plotagem da matriz de confusão\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular as métricas \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "accuracy = accuracy_score(y_t, y_p_rf)\n",
    "recall = recall_score(y_t, y_p_rf)\n",
    "precision = precision_score(y_t, y_p_rf)\n",
    "f1 = f1_score(y_t, y_p_rf)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precisão: {precision}')\n",
    "print(f'F1-Score: {f1}')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calcula a curva ROC e a área sob a curva ROC (ROC AUC)\n",
    "fpr, tpr, thresholds = roc_curve(y_t, y_pp_rf)\n",
    "roc_auc = roc_auc_score(y_t, y_pp_rf)\n",
    "\n",
    "# Plotar a curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (área = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Exibir a plotagem da curva ROC\n",
    "plt.show()\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "cm = confusion_matrix(y_t, y_p_rf)\n",
    "\n",
    "# Definir rótulos das classes\n",
    "class_labels = ['Classe 0', 'Classe 1']\n",
    "\n",
    "# Plotar a matriz de confusão como um gráfico\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusao')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "\n",
    "# Adiciona os valores da matriz de confusão nas células da matriz\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Predição')\n",
    "\n",
    "# Exibe a plotagem da matriz de confusão\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_rf = np.where(np.array(y_pp_rf) >=0.45,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular as métricas \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "accuracy = accuracy_score(y_t, y_p_rf)\n",
    "recall = recall_score(y_t, y_p_rf)\n",
    "precision = precision_score(y_t, y_p_rf)\n",
    "f1 = f1_score(y_t, y_p_rf)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precisão: {precision}')\n",
    "print(f'F1-Score: {f1}')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calcula a curva ROC e a área sob a curva ROC (ROC AUC)\n",
    "fpr, tpr, thresholds = roc_curve(y_t, y_pp_rf)\n",
    "roc_auc = roc_auc_score(y_t, y_pp_rf)\n",
    "\n",
    "# Plotar a curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (área = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Exibir a plotagem da curva ROC\n",
    "plt.show()\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "cm = confusion_matrix(y_t, y_p_rf)\n",
    "\n",
    "# Definir rótulos das classes\n",
    "class_labels = ['Classe 0', 'Classe 1']\n",
    "\n",
    "# Plotar a matriz de confusão como um gráfico\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusao')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "\n",
    "# Adiciona os valores da matriz de confusão nas células da matriz\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Predição')\n",
    "\n",
    "# Exibe a plotagem da matriz de confusão\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular as métricas \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "accuracy = accuracy_score(y_t, y_p_nn)\n",
    "recall = recall_score(y_t, y_p_nn)\n",
    "precision = precision_score(y_t, y_p_nn)\n",
    "f1 = f1_score(y_t, y_p_nn)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f'Acurácia: {accuracy}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Precisão: {precision}')\n",
    "print(f'F1-Score: {f1}')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Calcula a curva ROC e a área sob a curva ROC (ROC AUC)\n",
    "fpr, tpr, thresholds = roc_curve(y_t, y_pp_nn)\n",
    "roc_auc = roc_auc_score(y_t, y_pp_nn)\n",
    "\n",
    "# Plotar a curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (área = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Exibir a plotagem da curva ROC\n",
    "plt.show()\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "cm = confusion_matrix(y_t, y_p_nn)\n",
    "\n",
    "# Definir rótulos das classes\n",
    "class_labels = ['Classe 0', 'Classe 1']\n",
    "\n",
    "# Plotar a matriz de confusão como um gráfico\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusao')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "\n",
    "# Adiciona os valores da matriz de confusão nas células da matriz\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Predição')\n",
    "\n",
    "# Exibe a plotagem da matriz de confusão\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas que vao ser armazenadas os resultados das predicoes e os verdadeiros valores\n",
    "# pp = resultados em probabilidade e p em classe\n",
    "# rf = randomforest, xg = xgboost, nn = redes neurais\n",
    "y_t = []\n",
    "y_p_rf = []\n",
    "y_pp_rf = []\n",
    "df_feat_imp = pd.DataFrame()\n",
    "\n",
    "for i in (range(40)):\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        # Dividir os dados em conjuntos de treinamento e teste\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # pre processamento ja bisto \n",
    "        for col in X_train.columns:\n",
    "            indexs = X_train[X_train[col].isnull()].index\n",
    "            if len(X_train[col].dropna().unique()) > 2:\n",
    "                df_desc = X_train[col].describe().T\n",
    "                DQ = df_desc['75%'] - df_desc['25%']\n",
    "                limite_inferior = df_desc['25%'] - 1.5*DQ\n",
    "                limite_superior = df_desc['75%'] + 1.5*DQ\n",
    "                X_train.loc[(X_train[col] > limite_superior), col] = limite_superior\n",
    "                X_train.loc[(X_train[col] < limite_inferior), col] = limite_inferior\n",
    "                X_test.loc[(X_test[col] > limite_superior), col] = limite_superior\n",
    "                X_test.loc[(X_test[col] < limite_inferior), col] = limite_inferior\n",
    "                if len(indexs) > 0:\n",
    "                    X_train[\"%s_nulo\" % col] = 0\n",
    "                    X_train.loc[indexs, \"%s_nulo\" % col] = 1\n",
    "                    X_train.loc[indexs, col] = X_train[col].mean()\n",
    "            else:\n",
    "                if len(indexs) > 0:\n",
    "                    X_train[\"%s_nulo\" % col] = 0\n",
    "                    X_train.loc[indexs, col] = 0\n",
    "                    X_train.loc[indexs, \"%s_nulo\" % col] = X_train[col].mode().values[0]\n",
    "        for col in X_test.columns:\n",
    "            indexs = X_test[X_test[col].isnull()].index\n",
    "            if len(indexs) > 0:\n",
    "                if len(X_train[col].dropna().unique()) > 2:\n",
    "                    X_test[\"%s_nulo\" % col] = 0\n",
    "                    X_test.loc[indexs, col] = 0\n",
    "                    X_test.loc[indexs, \"%s_nulo\" % col] = X_train[col].mode().values[0]\n",
    "                else:\n",
    "                    X_test[\"%s_nulo\" % col] = 0\n",
    "                    X_test.loc[indexs, \"%s_nulo\" % col] = 1\n",
    "                    X_test.loc[indexs, col] = X_train[col].mean()\n",
    "        for col1 in X_train.columns:\n",
    "            if col1 not in X_test.columns:\n",
    "                X_test[col1] = 0\n",
    "        X_test = X_test[X_train.columns.tolist()]\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(X_train)\n",
    "        X_train_data = sc.transform(X_train)\n",
    "        X_train = pd.DataFrame(X_train_data, columns = X_train.columns)\n",
    "        X_test_data = sc.transform(X_test)\n",
    "        X_test = pd.DataFrame(X_test_data,columns=X_test.columns)\n",
    "       \n",
    "        # define os modelos com os hiperparametros do gridsearch\n",
    "        random_forest = RandomForestClassifier(**params_rf)\n",
    "        \n",
    "        #treina os modelos\n",
    "        random_forest.fit(X_train, y_train)\n",
    "\n",
    "        #armazena as predicoes em probabilidade e classe e o resultado real\n",
    "        y_t.extend(y_test)\n",
    "        y_p_rf.extend(random_forest.predict(X_test))\n",
    "        y_pp_rf.extend(random_forest.predict_proba(X_test)[:,1])\n",
    "        df_aux = pd.DataFrame({\"val_rf\":random_forest.feature_importances_, \"var\" : X_test.columns})\n",
    "        df_feat_imp = pd.concat([df_feat_imp,df_aux])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_rf = df_feat_imp.groupby(\"var\").mean().reset_index().sort_values(\"val_rf\", ascending= False)\n",
    "\n",
    "# Plotar a importância das características\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_importances_rf)), feature_importances_rf['val_rf'])\n",
    "plt.xticks(range(len(feature_importances_rf)), feature_importances_rf['var'], rotation=90)\n",
    "plt.xlabel('Características')\n",
    "plt.ylabel('Importância')\n",
    "plt.title('Importância das Características')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Cria um novo modelo com os parametros escolhidos anteriormente\n",
    "rcf = RandomForestClassifier(**params_rf)\n",
    "\n",
    "#Realiza as tecnicas de pre processamento de dados\n",
    "X = df.drop(columns = alvo)\n",
    "y = df[alvo]\n",
    "\n",
    "for col in X.columns:\n",
    "    if len(X[col].dropna().unique()) > 2:\n",
    "        # .T transpoe o dataframe \n",
    "        # DQ = distancia interquartil   \n",
    "        df_desc = X[col].describe().T\n",
    "        DQ = df_desc['75%'] - df_desc['25%']\n",
    "        limite_inferior = df_desc['25%'] - 1.5*DQ\n",
    "        limite_superior = df_desc['75%'] + 1.5*DQ\n",
    "        # atribui valor nulo aos outliers\n",
    "        X.loc[(X[col] > limite_superior), col] = limite_superior\n",
    "        X.loc[(X[col] < limite_inferior), col] = limite_inferior\n",
    "for col in X.columns:\n",
    "    indexs = X[X[col].isnull()].index\n",
    "    if len(indexs) > 0:\n",
    "        if len(X[col].dropna().unique()) <= 2:\n",
    "            X[\"%s_nulo\" % col] = 0\n",
    "            X.loc[indexs, col] = X[col].mode().values[0]\n",
    "            X.loc[indexs, \"%s_nulo\" % col] =  1\n",
    "        else:\n",
    "            X[\"%s_nulo\" % col] = 0\n",
    "            X.loc[indexs, \"%s_nulo\" % col] = 1\n",
    "            X.loc[indexs, col] = X[col].mean()\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_data = sc.transform(X)\n",
    "X = pd.DataFrame(X_data, columns = X.columns)\n",
    "\n",
    "#treina o modelo\n",
    "rcf.fit(X,y)\n",
    "#novo paciente com tudo = 1\n",
    "novo_paciente = np.array([1 for i in range(len(X.columns))]).reshape(1, -1)\n",
    "#os dados com o standard scaler\n",
    "novo_paciente_sc = sc.transform(novo_paciente)\n",
    "print(f\"probabilidade de morte dentro de um ano: {round(rcf.predict_proba(novo_paciente_sc)[0][1],2)}\")\n",
    "# Objeto interpretador do modelo do shap\n",
    "explainer = shap.TreeExplainer(rcf)\n",
    "#valores das importancias dos atributos\n",
    "shap_values = explainer.shap_values(novo_paciente_sc)\n",
    "#valor base que é a média das predições da amostra de treino, pois o waterfall \n",
    "# vai partir deste valor base para até a predicao final\n",
    "base_value = np.mean(y)\n",
    "print(f\"média base do modelo: {round(base_value,2)}\")\n",
    "shap.plots._waterfall.waterfall_legacy(expected_value=base_value, shap_values=shap_values[1][0], feature_names=X.columns, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = alvo)\n",
    "for col in X.columns:\n",
    "    if len(X[col].dropna().unique()) > 2:\n",
    "        # .T transpoe o dataframe \n",
    "        # DQ = distancia interquartil   \n",
    "        df_desc = X[col].describe().T\n",
    "        DQ = df_desc['75%'] - df_desc['25%']\n",
    "        limite_inferior = df_desc['25%'] - 1.5*DQ\n",
    "        limite_superior = df_desc['75%'] + 1.5*DQ\n",
    "        # atribui valor nulo aos outliers\n",
    "        X.loc[(X[col] > limite_superior), col] = limite_superior\n",
    "        X.loc[(X[col] < limite_inferior), col] = limite_inferior\n",
    "X[['ferro','Hemoglobina','fosfatase_alcalina']].describe().loc['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(rcf, \"modelo_random_forest.joblib\")\n",
    "joblib.dump(sc, 'scaler.pkl')\n",
    "df_means = X.describe().loc['mean'].reset_index()\n",
    "df_means.columns = ['col','media']\n",
    "df_means.to_csv(\"medias.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "126211920db30cf11ced6da537a1eb44101e5cb1dc0269d09ace8dfadcdc7a8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
